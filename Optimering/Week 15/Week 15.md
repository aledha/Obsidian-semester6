Summary:

The goal is to develop a method for solving non-smooth optimization problems, focusing on non-smooth regression and elastic net regression. The problem is that the L1 norm is non-differentiable at points where any element of x is equal to 0. The Karush-Kuhn-Tucker (KKT) conditions are necessary optimality conditions when constraint qualifications hold. By considering the Lagrangian and primal and dual problems, one can study the relation between the primal and dual problems. The example given is the L1 regression, which can be rewritten and solved using the Lagrangian and dual problem. The relation between the primal and dual problem is established using a lemma, which is a consequence of a general result.

[[Lagrangian duality]]   
Primal and dual linear programmes   
Weak duality   
Saddle points   
Strong duality for convex problems